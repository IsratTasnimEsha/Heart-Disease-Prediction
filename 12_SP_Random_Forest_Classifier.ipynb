{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import joblib\n",
    "os.chdir('Resources/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('10_SP_Preprocessed_Data.csv')\n",
    "\n",
    "X = df.drop(['HeartDisease'], axis='columns')\n",
    "Y = df[['HeartDisease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9456066945606695\n"
     ]
    }
   ],
   "source": [
    "# 1 - RF (F1)\n",
    "#-------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1786)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1397)\n",
    "    \n",
    "model_rf = rf.fit(X_train, Y_train)\n",
    "    \n",
    "pred_rf = model_rf.predict(X_test)\n",
    "    \n",
    "f1_rf = f1_score(Y_test, pred_rf)\n",
    "    \n",
    "print(f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9385245901639344\n"
     ]
    }
   ],
   "source": [
    "# 2 - RF+PCA (F1)\n",
    "#-----------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=1745)\n",
    "rf_model_pca = RandomForestClassifier(random_state=1745, n_estimators=100)\n",
    "\n",
    "X_train_pca, X_test_pca, Y_train_pca, Y_test_pca = train_test_split(X, Y, test_size=0.2, random_state=159)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_pca)\n",
    "X_test_pca = pca.transform(X_test_pca)\n",
    "\n",
    "rf_model_pca.fit(X_train_pca, Y_train_pca)\n",
    "Y_pred_pca = rf_model_pca.predict(X_test_pca)\n",
    "\n",
    "f1_rf_pca = f1_score(Y_test_pca, Y_pred_pca)\n",
    "\n",
    "print(f1_rf_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9421841541755889\n"
     ]
    }
   ],
   "source": [
    "# 3 - RF+IF (F1)\n",
    "#----------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "\n",
    "_if = IsolationForest(contamination=0.05, random_state=227, n_estimators=100, max_samples=256)\n",
    "\n",
    "outlier_predictions_if = _if.fit_predict(X)\n",
    "\n",
    "X_filtered_if = X[outlier_predictions_if != -1].reset_index(drop=True)\n",
    "Y_filtered_if = Y[outlier_predictions_if != -1].reset_index(drop=True)\n",
    "\n",
    "X_train_if, X_test_if, Y_train_if, Y_test_if = train_test_split(\n",
    "    X_filtered_if, Y_filtered_if, test_size=0.2, random_state=227\n",
    ")\n",
    "\n",
    "rf_model_if = RandomForestClassifier(random_state=227, n_estimators=94, max_depth=18, criterion='gini')\n",
    "rf_model_if.fit(X_train_if, Y_train_if)\n",
    "\n",
    "Y_pred_if = rf_model_if.predict(X_test_if)\n",
    "\n",
    "f1_rf_if = f1_score(Y_test_if, Y_pred_if)\n",
    "\n",
    "print(f1_rf_if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9478079331941545\n"
     ]
    }
   ],
   "source": [
    "# 4 - RF+XGB (F1)\n",
    "#-----------------\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "    \n",
    "X_train_rf_xgb, X_test_rf_xgb, Y_train_rf_xgb, Y_test_rf_xgb = train_test_split(X, Y, test_size=0.2, random_state=1786)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1397, n_estimators=99, criterion='gini', \n",
    "                                max_features=3, max_depth=19, min_samples_split=2)\n",
    "rf.fit(X_train_rf_xgb, Y_train_rf_xgb)\n",
    "rf_pred = rf.predict(X_test_rf_xgb)\n",
    "rf_f1 = f1_score(Y_test_rf_xgb, rf_pred)\n",
    "    \n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=1397)\n",
    "xgb.fit(X_train_rf_xgb, Y_train_rf_xgb)\n",
    "xgb_pred = xgb.predict(X_test_rf_xgb)\n",
    "xgb_f1 = f1_score(Y_test_rf_xgb, xgb_pred)\n",
    "    \n",
    "combined_pred = []\n",
    "for r, x in zip(rf_pred, xgb_pred):\n",
    "    combined_pred.append(r if r == x else r)\n",
    "    \n",
    "f1_rf_xgb = f1_score(Y_test_rf_xgb, combined_pred)\n",
    "    \n",
    "print(f1_rf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_test_rf_xgb: 329\n",
      "Length of rf_pred: 329\n",
      "Length of xgb_pred: 329\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of X_test_rf_xgb:\", len(X_test_rf_xgb))\n",
    "print(\"Length of rf_pred:\", len(rf_pred))\n",
    "print(\"Length of xgb_pred:\", len(xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12_SP_Model_RF_XGB.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "_, X_test_indices = train_test_split(np.arange(len(X)), test_size=0.2, random_state=1786)\n",
    "\n",
    "with open('12_SP_Test_Data_RF_XGB.txt', 'w') as f:\n",
    "    f.write(str([list(X_test_indices)]))\n",
    "\n",
    "with open('12_SP_F1_Score_RF_XGB.txt', 'w') as f:\n",
    "    f.write(f\"{f1_rf_xgb}\\n\")\n",
    "\n",
    "joblib.dump({'rf': rf, 'xgb': xgb}, '12_SP_Model_RF_XGB.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9421841541755889\n"
     ]
    }
   ],
   "source": [
    "# 5 - RF+IF+XGB (F1)\n",
    "#--------------------\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=227, n_estimators=100, max_samples=256)\n",
    "outliers = iso_forest.fit_predict(X)\n",
    "X_filtered = X[outliers != -1].reset_index(drop=True)\n",
    "Y_filtered = Y[outliers != -1].reset_index(drop=True)\n",
    "\n",
    "X_train_rf_if_xgb, X_test_rf_if_xgb, Y_train_rf_if_xgb, Y_test_rf_if_xgb = train_test_split(\n",
    "    X_filtered, Y_filtered, test_size=0.2, random_state=227\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=227, n_estimators=94, max_depth=18, max_features=3)\n",
    "rf.fit(X_train_rf_if_xgb, Y_train_rf_if_xgb)\n",
    "rf_pred = rf.predict(X_test_rf_if_xgb)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=227)\n",
    "xgb.fit(X_train_rf_if_xgb, Y_train_rf_if_xgb)\n",
    "xgb_pred = xgb.predict(X_test_rf_if_xgb)\n",
    "\n",
    "combined_pred = []\n",
    "for r, x in zip(rf_pred, xgb_pred):\n",
    "    combined_pred.append(r if r == x else r)\n",
    "\n",
    "f1_rf_if_xgb = f1_score(Y_test_rf_if_xgb, combined_pred)\n",
    "\n",
    "print(f1_rf_if_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9240121580547113\n"
     ]
    }
   ],
   "source": [
    "# 6 - RF+XGB (ACC)\n",
    "#-----------------\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "X_train_rf_xgb, X_test_rf_xgb, Y_train_rf_xgb, Y_test_rf_xgb = train_test_split(X, Y, test_size=0.2, random_state=1786)\n",
    "    \n",
    "rf = RandomForestClassifier(random_state=1397, n_estimators=99)\n",
    "rf.fit(X_train_rf_xgb, Y_train_rf_xgb)\n",
    "rf_pred = rf.predict(X_test_rf_xgb)\n",
    "rf_f1 = accuracy_score(Y_test_rf_xgb, rf_pred)\n",
    "    \n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=1397)\n",
    "xgb.fit(X_train_rf_xgb, Y_train_rf_xgb)\n",
    "xgb_pred = xgb.predict(X_test_rf_xgb)\n",
    "xgb_acc = accuracy_score(Y_test_rf_xgb, xgb_pred)\n",
    "    \n",
    "combined_pred = []\n",
    "for r, x in zip(rf_pred, xgb_pred):\n",
    "    combined_pred.append(r if r == x else r)\n",
    "    \n",
    "combined_acc = accuracy_score(Y_test_rf_xgb, combined_pred)\n",
    "    \n",
    "print(combined_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('12_SP_ACC_Score_RF_XGB.txt', 'w') as f:\n",
    "    f.write(f\"{combined_acc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9432314410480349\n"
     ]
    }
   ],
   "source": [
    "# 7 - RF+XGB (PRE)\n",
    "#-----------------\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "X_train_rf_xgb, X_test_rf_xgb, Y_train_rf_xgb, Y_test_rf_xgb = train_test_split(X, Y, test_size=0.2, random_state=3830)\n",
    "    \n",
    "rf = RandomForestClassifier(random_state=101, n_estimators=12)\n",
    "rf.fit(X_train_rf_xgb, Y_train_rf_xgb)\n",
    "rf_pred = rf.predict(X_test_rf_xgb)\n",
    "rf_pre = precision_score(Y_test_rf_xgb, rf_pred)\n",
    "    \n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=101)\n",
    "xgb.fit(X_train_rf_xgb, Y_train_rf_xgb)\n",
    "xgb_pred = xgb.predict(X_test_rf_xgb)\n",
    "xgb_pre = precision_score(Y_test_rf_xgb, xgb_pred)\n",
    "    \n",
    "combined_pred = []\n",
    "for r, x in zip(rf_pred, xgb_pred):\n",
    "    combined_pred.append(r if r == x else r)\n",
    "    \n",
    "combined_pre = precision_score(Y_test_rf_xgb, combined_pred)\n",
    "    \n",
    "print(combined_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('12_SP_PRE_Score_RF_XGB.txt', 'w') as f:\n",
    "    f.write(f\"{combined_pre}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819819819819819\n"
     ]
    }
   ],
   "source": [
    "# 8 - RF+XGB (REC)\n",
    "#-----------------\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "X_train_rf_xgb, X_test_rf_xgb, Y_train_rf_xgb, Y_test_rf_xgb = train_test_split(X, Y, test_size=0.2, random_state=2351)\n",
    "    \n",
    "rf = RandomForestClassifier(random_state=1495, n_estimators=81)\n",
    "rf.fit(X_train_rf_xgb, Y_train_rf_xgb)\n",
    "rf_pred = rf.predict(X_test_rf_xgb)\n",
    "rf_rec = recall_score(Y_test_rf_xgb, rf_pred)\n",
    "    \n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=1495)\n",
    "xgb.fit(X_train_rf_xgb, Y_train_rf_xgb)\n",
    "xgb_pred = xgb.predict(X_test_rf_xgb)\n",
    "xgb_rec = recall_score(Y_test_rf_xgb, xgb_pred)\n",
    "    \n",
    "combined_pred = []\n",
    "for r, x in zip(rf_pred, xgb_pred):\n",
    "    combined_pred.append(r if r == x else r)\n",
    "    \n",
    "combined_rec = recall_score(Y_test_rf_xgb, combined_pred)\n",
    "\n",
    "print(combined_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('12_SP_REC_Score_RF_XGB.txt', 'w') as f:\n",
    "    f.write(f\"{combined_rec}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "RF:\t\t94.56%\n",
      "RF+PCA:\t\t93.85%\n",
      "RF+IF:\t\t94.22%\n",
      "RF+XGB:\t\t94.78%\n",
      "RF+IF+XGB:\t94.22%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score\")\n",
    "print(f'RF:\\t\\t{round(f1_rf * 100, 2)}%')\n",
    "print(f'RF+PCA:\\t\\t{round(f1_rf_pca * 100, 2)}%')\n",
    "print(f'RF+IF:\\t\\t{round(f1_rf_if * 100, 2)}%')\n",
    "print(f'RF+XGB:\\t\\t{round(f1_rf_xgb * 100, 2)}%')\n",
    "print(f'RF+IF+XGB:\\t{round(f1_rf_if_xgb * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
