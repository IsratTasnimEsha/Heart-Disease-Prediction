{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import joblib\n",
    "os.chdir('Resources/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('10_SP_Preprocessed_Data.csv')\n",
    "\n",
    "X = df.drop(['HeartDisease'], axis='columns')\n",
    "Y = df[['HeartDisease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "Processing fold 2\n",
      "Processing fold 3\n",
      "Processing fold 4\n",
      "Processing fold 5\n",
      "F1-scores for each fold: [0.8962472406181016, 0.8888888888888888, 0.9066666666666666, 0.89086859688196, 0.8755364806866953]\n",
      "Average F1-score: 0.8916415747484626 ± 0.011341454648932926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed=1786\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "    \n",
    "model_rf = rf.fit(X_train, Y_train)\n",
    "    \n",
    "pred_rf = model_rf.predict(X_test)\n",
    "    \n",
    "accuracy_rf = f1_score(Y_test, pred_rf)\n",
    "    \n",
    "print(accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "Processing fold 2\n",
      "Processing fold 3\n",
      "Processing fold 4\n",
      "Processing fold 5\n",
      "F1-scores for each fold: [0.8620689655172413, 0.8676789587852495, 0.888402625820569, 0.8565022421524664, 0.8665207877461707]\n",
      "Average F1-score: 0.8682347160043393 ± 0.010822739249102528\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "\n",
    "# Initialize PCA with desired number of components (e.g., 95% variance explained)\n",
    "pca = PCA(n_components=0.95, random_state=378)\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=378, n_estimators=99)\n",
    "\n",
    "# StratifiedKFold initialization\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=378)\n",
    "\n",
    "f1_scores = []\n",
    "test_indices_all_folds = []  # To store test indices for all folds as a list of lists\n",
    "\n",
    "# Open a text file to write the F1 scores\n",
    "with open(\"12_SP_F1_Scores_RF_PCA.txt\", \"w\") as f1_file:\n",
    "    # Loop over each fold for StratifiedKFold\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
    "        print(f\"Processing fold {fold + 1}\")\n",
    "\n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "        # Append test indices for this fold\n",
    "        test_indices_all_folds.append(list(X.index[test_index]))\n",
    "\n",
    "        # Apply PCA on the training and test data\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        # Train the RandomForest model\n",
    "        rf_model.fit(X_train_pca, Y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        Y_pred = rf_model.predict(X_test_pca)\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(Y_test, Y_pred)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Save the trained model for the current fold\n",
    "        joblib.dump(rf_model, f'12_SP_Model_RF_PCA_{fold + 1}.joblib')\n",
    "\n",
    "        # Write F1 score for the current fold to the text file\n",
    "        f1_file.write(f\"F1-score for fold {fold + 1}: {f1*100:.2f}\\n\")\n",
    "\n",
    "    # Calculate and write the average F1-score to the text file\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    std_f1 = np.std(f1_scores)\n",
    "    f1_file.write(f\"\\nAverage F1-score: {avg_f1*100:.2f} ± {std_f1*100:.2f}\\n\")\n",
    "\n",
    "# Save the list of test indices to a file\n",
    "with open(\"12_SP_Test_Data_RF_PCA.txt\", \"w\") as test_file:\n",
    "    test_file.write(str(test_indices_all_folds))\n",
    "\n",
    "# Print F1-scores for each fold and their average\n",
    "print(f\"F1-scores for each fold: {f1_scores}\")\n",
    "print(f\"Average F1-score: {avg_f1} ± {std_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 1642\n",
      "Filtered dataset size: 1559 (outliers removed)\n",
      "Processing fold 1\n",
      "Processing fold 2\n",
      "Processing fold 3\n",
      "Processing fold 4\n",
      "Processing fold 5\n",
      "F1-scores for each fold: [0.9002320185614849, 0.8812785388127854, 0.8976744186046511, 0.8899082568807339, 0.8878923766816144]\n",
      "Average F1-score: 0.891397121908254 ± 0.006846101587350254\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "\n",
    "# Initialize Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=1649, max_samples=256)  # Adjust contamination to expected outlier fraction\n",
    "\n",
    "# Fit Isolation Forest on the features\n",
    "outlier_predictions = iso_forest.fit_predict(X)\n",
    "\n",
    "# Identify and remove outliers (label -1 indicates outliers)\n",
    "X_filtered = X[outlier_predictions != -1].copy()\n",
    "Y_filtered = Y[outlier_predictions != -1].copy()\n",
    "\n",
    "# Retain original indices\n",
    "X_filtered['Original_Index'] = X.index[outlier_predictions != -1]\n",
    "\n",
    "print(f\"Original dataset size: {X.shape[0]}\")\n",
    "print(f\"Filtered dataset size: {X_filtered.shape[0]} (outliers removed)\")\n",
    "\n",
    "# Initialize Random Forest and Stratified K-Fold\n",
    "rf_model = RandomForestClassifier(random_state=1649, n_estimators=339)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1649)\n",
    "\n",
    "f1_scores = []\n",
    "test_indices_all_folds = []  # To store test indices for all folds\n",
    "\n",
    "# Open a text file to write the results\n",
    "with open(\"12_SP_F1_Scores_RF_IF.txt\", \"w\") as f1_file:\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X_filtered.iloc[:, :-1], Y_filtered)):\n",
    "        print(f\"Processing fold {fold + 1}\")\n",
    "\n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test = X_filtered.iloc[train_index, :-1], X_filtered.iloc[test_index, :-1]\n",
    "        Y_train, Y_test = Y_filtered.iloc[train_index], Y_filtered.iloc[test_index]\n",
    "\n",
    "        # Append original test indices for this fold\n",
    "        test_indices_all_folds.append(list(X_filtered['Original_Index'].iloc[test_index]))\n",
    "\n",
    "        # Train the RandomForest model\n",
    "        rf_model.fit(X_train, Y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        Y_pred = rf_model.predict(X_test)\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(Y_test, Y_pred)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Save the trained model for the current fold\n",
    "        joblib.dump(rf_model, f'12_SP_Model_RF_IF_{fold + 1}.joblib')\n",
    "\n",
    "        # Write F1 score for the current fold to the text file\n",
    "        f1_file.write(f\"F1-score for fold {fold + 1}: {f1*100:.2f}\\n\")\n",
    "\n",
    "    # Calculate and write the average F1-score to the text file\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    std_f1 = np.std(f1_scores)\n",
    "    f1_file.write(f\"\\nAverage F1-score: {avg_f1*100:.2f} ± {std_f1*100:.2f}\\n\")\n",
    "\n",
    "# Save the original test indices of all folds to a file\n",
    "with open(\"12_SP_Test_Data_RF_IF.txt\", \"w\") as test_file:\n",
    "    test_file.write(str(test_indices_all_folds))\n",
    "\n",
    "# Print F1-scores for each fold and their average\n",
    "print(f\"F1-scores for each fold: {f1_scores}\")\n",
    "print(f\"Average F1-score: {avg_f1} ± {std_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing fold 2\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing fold 3\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing fold 4\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing fold 5\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "F1-scores for each fold: [0.8898678414096917, 0.8552036199095022, 0.8604118993135011, 0.8597285067873304, 0.8433179723502304]\n",
      "Average F1-score: 0.8617059679540511 ± 0.015356269047281197\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 417\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# Initialize StratifiedKFold for 10-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# List to hold F1-scores for each fold\n",
    "f1_scores = []\n",
    "\n",
    "# List to store test indices for all folds\n",
    "test_indices_all_folds = []\n",
    "\n",
    "# Loop over each fold\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
    "    print(f\"Processing fold {fold + 1}\")\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Append test indices for this fold\n",
    "    test_indices_all_folds.append(list(X.index[test_index]))\n",
    "\n",
    "    # Reshape data for LSTM (3D input)\n",
    "    X_train_reshaped = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test_reshaped = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(11, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dropout(0.01 * 5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "    optimizer = Adam(learning_rate=1 / 15)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Train the LSTM model\n",
    "    model.fit(X_train_reshaped, Y_train, epochs=42, batch_size=40, verbose=0)\n",
    "\n",
    "    # Use the trained LSTM to extract features (predictions)\n",
    "    X_train_features = model.predict(X_train_reshaped)\n",
    "    X_test_features = model.predict(X_test_reshaped)\n",
    "\n",
    "    # Train Random Forest on LSTM features\n",
    "    rf_lstm = RandomForestClassifier(n_estimators=76, random_state=seed)\n",
    "    rf_lstm.fit(X_train_features, Y_train.values.ravel())\n",
    "\n",
    "    # Predict on the test set and compute F1 score\n",
    "    Y_pred = rf_lstm.predict(X_test_features)\n",
    "    performance_lstm = f1_score(Y_test, Y_pred)\n",
    "\n",
    "    f1_scores.append(performance_lstm)\n",
    "\n",
    "    # Save both LSTM and RF model in a single joblib file per fold\n",
    "    joblib.dump({'LSTM': model, 'RF': rf_lstm}, f'12_SP_Model_RF_LSTM_{fold + 1}.joblib')\n",
    "\n",
    "# Save F1-scores to a text file (10 F1 scores for each fold)\n",
    "with open('12_SP_F1_Scores_RF_LSTM.txt', 'w') as f:\n",
    "    for i, score in enumerate(f1_scores):\n",
    "        f.write(f\"F1-Score for fold {i + 1}: {score * 100: .2f}\\n\")\n",
    "\n",
    "    # Calculate and write the average F1 score at the end of the file\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    std_f1 = np.std(f1_scores)\n",
    "    f.write(f\"\\nAverage F1-score: {avg_f1*100: .2f} ± {std_f1*100: .2f}\\n\")\n",
    "\n",
    "# Save test indices of all folds to a file\n",
    "with open(\"12_SP_Test_Data_RF_LSTM.txt\", \"w\") as test_file:\n",
    "    test_file.write(str(test_indices_all_folds))\n",
    "\n",
    "# Print F1-scores and average\n",
    "print(f\"F1-scores for each fold: {f1_scores}\")\n",
    "print(f\"Average F1-score: {avg_f1} ± {std_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
