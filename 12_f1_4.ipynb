{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import joblib\n",
    "os.chdir('Resources/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('10_SP_Preprocessed_Data.csv')\n",
    "\n",
    "X = df.drop(['HeartDisease'], axis='columns')\n",
    "Y = df[['HeartDisease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9130434782608695 0.9130434782608695 1\n",
      "2 0.9146608315098468 0.9146608315098468 2\n",
      "3 0.9186813186813186 0.9186813186813186 3\n",
      "4 0.9203539823008849 0.9203539823008849 4\n",
      "5 0.9135254988913526 0.9203539823008849 4\n",
      "6 0.9175946547884187 0.9203539823008849 4\n",
      "7 0.9131403118040089 0.9203539823008849 4\n",
      "8 0.90625 0.9203539823008849 4\n",
      "9 0.9086859688195991 0.9203539823008849 4\n",
      "10 0.9107142857142857 0.9203539823008849 4\n",
      "11 0.912751677852349 0.9203539823008849 4\n",
      "12 0.9172259507829977 0.9203539823008849 4\n",
      "13 0.9123595505617977 0.9203539823008849 4\n",
      "14 0.9123595505617977 0.9203539823008849 4\n",
      "15 0.9147982062780269 0.9203539823008849 4\n",
      "16 0.9172259507829977 0.9203539823008849 4\n",
      "17 0.9147982062780269 0.9203539823008849 4\n",
      "18 0.9123595505617977 0.9203539823008849 4\n",
      "19 0.9123595505617977 0.9203539823008849 4\n",
      "20 0.912751677852349 0.9203539823008849 4\n",
      "21 0.9123595505617977 0.9203539823008849 4\n",
      "22 0.9078651685393259 0.9203539823008849 4\n",
      "23 0.9144144144144144 0.9203539823008849 4\n",
      "24 0.9103139013452914 0.9203539823008849 4\n",
      "25 0.9144144144144144 0.9203539823008849 4\n",
      "26 0.9078651685393259 0.9203539823008849 4\n",
      "27 0.903370786516854 0.9203539823008849 4\n",
      "28 0.9082774049217002 0.9203539823008849 4\n",
      "29 0.9082774049217002 0.9203539823008849 4\n",
      "30 0.905829596412556 0.9203539823008849 4\n",
      "31 0.9103139013452914 0.9203539823008849 4\n",
      "32 0.9103139013452914 0.9203539823008849 4\n",
      "33 0.9103139013452914 0.9203539823008849 4\n",
      "34 0.8979591836734694 0.9203539823008849 4\n",
      "35 0.9054054054054054 0.9203539823008849 4\n",
      "36 0.9020501138952164 0.9203539823008849 4\n",
      "37 0.9 0.9203539823008849 4\n",
      "38 0.9049773755656109 0.9203539823008849 4\n",
      "39 0.8995433789954338 0.9203539823008849 4\n",
      "40 0.9020501138952164 0.9203539823008849 4\n",
      "41 0.9020501138952164 0.9203539823008849 4\n",
      "42 0.9020501138952164 0.9203539823008849 4\n",
      "43 0.9020501138952164 0.9203539823008849 4\n",
      "44 0.9020501138952164 0.9203539823008849 4\n",
      "45 0.9 0.9203539823008849 4\n",
      "46 0.9045454545454545 0.9203539823008849 4\n",
      "47 0.89749430523918 0.9203539823008849 4\n",
      "48 0.9 0.9203539823008849 4\n",
      "49 0.89749430523918 0.9203539823008849 4\n",
      "50 0.8995433789954338 0.9203539823008849 4\n",
      "51 0.8995433789954338 0.9203539823008849 4\n",
      "52 0.8995433789954338 0.9203539823008849 4\n",
      "53 0.8995433789954338 0.9203539823008849 4\n",
      "54 0.9 0.9203539823008849 4\n",
      "55 0.89749430523918 0.9203539823008849 4\n",
      "56 0.8995433789954338 0.9203539823008849 4\n",
      "57 0.9020501138952164 0.9203539823008849 4\n",
      "58 0.9041095890410958 0.9203539823008849 4\n",
      "59 0.9061784897025171 0.9203539823008849 4\n",
      "60 0.9036697247706422 0.9203539823008849 4\n",
      "61 0.9016018306636155 0.9203539823008849 4\n",
      "62 0.897025171624714 0.9203539823008849 4\n",
      "63 0.9 0.9203539823008849 4\n",
      "64 0.9020501138952164 0.9203539823008849 4\n",
      "65 0.8995433789954338 0.9203539823008849 4\n",
      "66 0.9041095890410958 0.9203539823008849 4\n",
      "67 0.9061784897025171 0.9203539823008849 4\n",
      "68 0.9061784897025171 0.9203539823008849 4\n",
      "69 0.9061784897025171 0.9203539823008849 4\n",
      "70 0.9061784897025171 0.9203539823008849 4\n",
      "71 0.9061784897025171 0.9203539823008849 4\n",
      "72 0.9061784897025171 0.9203539823008849 4\n",
      "73 0.9041095890410958 0.9203539823008849 4\n",
      "74 0.9041095890410958 0.9203539823008849 4\n",
      "75 0.9041095890410958 0.9203539823008849 4\n",
      "76 0.9066059225512528 0.9203539823008849 4\n",
      "77 0.9066059225512528 0.9203539823008849 4\n",
      "78 0.9045454545454545 0.9203539823008849 4\n",
      "79 0.9041095890410958 0.9203539823008849 4\n",
      "80 0.9041095890410958 0.9203539823008849 4\n",
      "81 0.9061784897025171 0.9203539823008849 4\n",
      "82 0.9061784897025171 0.9203539823008849 4\n",
      "83 0.9061784897025171 0.9203539823008849 4\n",
      "84 0.9061784897025171 0.9203539823008849 4\n",
      "85 0.9061784897025171 0.9203539823008849 4\n",
      "86 0.9041095890410958 0.9203539823008849 4\n",
      "87 0.908256880733945 0.9203539823008849 4\n",
      "88 0.908256880733945 0.9203539823008849 4\n",
      "89 0.908256880733945 0.9203539823008849 4\n",
      "90 0.908256880733945 0.9203539823008849 4\n",
      "91 0.908256880733945 0.9203539823008849 4\n",
      "92 0.908256880733945 0.9203539823008849 4\n",
      "93 0.9061784897025171 0.9203539823008849 4\n",
      "94 0.9061784897025171 0.9203539823008849 4\n",
      "95 0.908256880733945 0.9203539823008849 4\n",
      "96 0.908256880733945 0.9203539823008849 4\n",
      "97 0.908256880733945 0.9203539823008849 4\n",
      "98 0.908256880733945 0.9203539823008849 4\n",
      "99 0.908256880733945 0.9203539823008849 4\n",
      "100 0.908256880733945 0.9203539823008849 4\n",
      "101 0.908256880733945 0.9203539823008849 4\n",
      "102 0.908256880733945 0.9203539823008849 4\n",
      "103 0.9061784897025171 0.9203539823008849 4\n",
      "104 0.9061784897025171 0.9203539823008849 4\n",
      "105 0.9061784897025171 0.9203539823008849 4\n",
      "106 0.9061784897025171 0.9203539823008849 4\n",
      "107 0.9041095890410958 0.9203539823008849 4\n",
      "108 0.9061784897025171 0.9203539823008849 4\n",
      "109 0.9041095890410958 0.9203539823008849 4\n",
      "110 0.9041095890410958 0.9203539823008849 4\n",
      "111 0.9041095890410958 0.9203539823008849 4\n",
      "112 0.9 0.9203539823008849 4\n",
      "113 0.9041095890410958 0.9203539823008849 4\n",
      "114 0.9061784897025171 0.9203539823008849 4\n",
      "115 0.9041095890410958 0.9203539823008849 4\n",
      "116 0.9041095890410958 0.9203539823008849 4\n",
      "117 0.9061784897025171 0.9203539823008849 4\n",
      "118 0.9041095890410958 0.9203539823008849 4\n",
      "119 0.9061784897025171 0.9203539823008849 4\n",
      "120 0.9061784897025171 0.9203539823008849 4\n",
      "121 0.9041095890410958 0.9203539823008849 4\n",
      "122 0.9041095890410958 0.9203539823008849 4\n",
      "123 0.9061784897025171 0.9203539823008849 4\n",
      "124 0.908256880733945 0.9203539823008849 4\n",
      "125 0.9041095890410958 0.9203539823008849 4\n",
      "126 0.9041095890410958 0.9203539823008849 4\n",
      "127 0.9041095890410958 0.9203539823008849 4\n",
      "128 0.9020501138952164 0.9203539823008849 4\n",
      "129 0.9020501138952164 0.9203539823008849 4\n",
      "130 0.9020501138952164 0.9203539823008849 4\n",
      "131 0.9041095890410958 0.9203539823008849 4\n",
      "132 0.9041095890410958 0.9203539823008849 4\n",
      "133 0.9041095890410958 0.9203539823008849 4\n",
      "134 0.9061784897025171 0.9203539823008849 4\n",
      "135 0.9061784897025171 0.9203539823008849 4\n",
      "136 0.9041095890410958 0.9203539823008849 4\n",
      "137 0.9 0.9203539823008849 4\n",
      "138 0.8979591836734694 0.9203539823008849 4\n",
      "139 0.9041095890410958 0.9203539823008849 4\n",
      "140 0.9041095890410958 0.9203539823008849 4\n",
      "141 0.9041095890410958 0.9203539823008849 4\n",
      "142 0.9020501138952164 0.9203539823008849 4\n",
      "143 0.9020501138952164 0.9203539823008849 4\n",
      "144 0.9041095890410958 0.9203539823008849 4\n",
      "145 0.9041095890410958 0.9203539823008849 4\n",
      "146 0.9041095890410958 0.9203539823008849 4\n",
      "147 0.9041095890410958 0.9203539823008849 4\n",
      "148 0.9041095890410958 0.9203539823008849 4\n",
      "149 0.9020501138952164 0.9203539823008849 4\n",
      "150 0.9041095890410958 0.9203539823008849 4\n",
      "151 0.9041095890410958 0.9203539823008849 4\n",
      "152 0.9061784897025171 0.9203539823008849 4\n",
      "153 0.9061784897025171 0.9203539823008849 4\n",
      "154 0.9061784897025171 0.9203539823008849 4\n",
      "155 0.9 0.9203539823008849 4\n",
      "156 0.9 0.9203539823008849 4\n",
      "157 0.9041095890410958 0.9203539823008849 4\n",
      "158 0.9041095890410958 0.9203539823008849 4\n",
      "159 0.9020501138952164 0.9203539823008849 4\n",
      "160 0.9020501138952164 0.9203539823008849 4\n",
      "161 0.9041095890410958 0.9203539823008849 4\n",
      "162 0.9020501138952164 0.9203539823008849 4\n",
      "163 0.9020501138952164 0.9203539823008849 4\n",
      "164 0.9020501138952164 0.9203539823008849 4\n",
      "165 0.9020501138952164 0.9203539823008849 4\n",
      "166 0.8979591836734694 0.9203539823008849 4\n",
      "167 0.8979591836734694 0.9203539823008849 4\n",
      "168 0.8979591836734694 0.9203539823008849 4\n",
      "169 0.8979591836734694 0.9203539823008849 4\n",
      "170 0.8979591836734694 0.9203539823008849 4\n",
      "171 0.9 0.9203539823008849 4\n",
      "172 0.9 0.9203539823008849 4\n",
      "173 0.9 0.9203539823008849 4\n",
      "174 0.8959276018099548 0.9203539823008849 4\n",
      "175 0.8959276018099548 0.9203539823008849 4\n",
      "176 0.8959276018099548 0.9203539823008849 4\n",
      "177 0.8959276018099548 0.9203539823008849 4\n",
      "178 0.8939051918735892 0.9203539823008849 4\n",
      "179 0.8939051918735892 0.9203539823008849 4\n",
      "180 0.8939051918735892 0.9203539823008849 4\n",
      "181 0.8959276018099548 0.9203539823008849 4\n",
      "182 0.8959276018099548 0.9203539823008849 4\n",
      "183 0.8959276018099548 0.9203539823008849 4\n",
      "184 0.8959276018099548 0.9203539823008849 4\n",
      "185 0.8959276018099548 0.9203539823008849 4\n",
      "186 0.8959276018099548 0.9203539823008849 4\n",
      "187 0.8959276018099548 0.9203539823008849 4\n",
      "188 0.8959276018099548 0.9203539823008849 4\n",
      "189 0.8959276018099548 0.9203539823008849 4\n",
      "190 0.8959276018099548 0.9203539823008849 4\n",
      "191 0.8959276018099548 0.9203539823008849 4\n",
      "192 0.8959276018099548 0.9203539823008849 4\n",
      "193 0.8959276018099548 0.9203539823008849 4\n",
      "194 0.8959276018099548 0.9203539823008849 4\n",
      "195 0.8959276018099548 0.9203539823008849 4\n",
      "196 0.8959276018099548 0.9203539823008849 4\n",
      "197 0.8959276018099548 0.9203539823008849 4\n",
      "198 0.8959276018099548 0.9203539823008849 4\n",
      "199 0.8959276018099548 0.9203539823008849 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "mx = 0\n",
    "ind = 0\n",
    "\n",
    "for i in range(1, 200):\n",
    "    seed = i\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2419)\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=314, n_estimators=97)\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=314, n_estimators=seed)\n",
    "    \n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[('rf', rf), ('xgb', xgb)],\n",
    "        voting='soft'\n",
    "    )\n",
    "    \n",
    "    # Train ensemble\n",
    "    ensemble.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    pred = ensemble.predict(X_test)\n",
    "    f1 = f1_score(Y_test, pred)\n",
    "    \n",
    "    if f1 > mx:\n",
    "        mx = f1\n",
    "        ind = i\n",
    "    \n",
    "    print(i, f1, mx, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
