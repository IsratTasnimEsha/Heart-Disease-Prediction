{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "os.chdir('Resources/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('7_CC_Encrypted_Data.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1822 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HeartDisease\n",
       "0                0\n",
       "1                1\n",
       "2                0\n",
       "3                1\n",
       "4                0\n",
       "...            ...\n",
       "1817             0\n",
       "1818             0\n",
       "1819             0\n",
       "1820             0\n",
       "1821             0\n",
       "\n",
       "[1822 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df[['HeartDisease']]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7270988666945721113120809463312144500555280693674 , 32083111036126459261180639309633731096371489192527\n",
      "22961665442842143903220898566890700943449852505536 , 50806696935996374692315166258825721820101871429809\n",
      "20613262322062277119573630365746595127182499134519 , 22816956567510665168741835293166565473220634279942\n",
      "25666449378145533821257044298909866450131224188388 , 43308947551399742961005592210604413184580574131025\n",
      "49648777350264920336257917599386766751429992537949 , 18080880950383506422733101513743633287139900422079\n",
      "23262138535430815965897209751063602705729030703607 , 36371123739210616465996057708704981096130718166775\n",
      "20663312364214574545779485666796513311973587596483 , 43229146032083899182761576784977586741533298306210\n",
      "52792865455644029778549137754509322291183002304751 , 29013720512811045293191661764715330706360614478768\n",
      "53567916807806914103914877537850847808169443022861 , 21498702084474512676857271979017679975982111913956\n",
      "22453991272873058234492300158377019032521111612219 , 20843916427861693662232393682374652836468951328859\n",
      "10235051201618776623875359480548401671315373635138 , 39630638501985917651015259219491768933792417479908\n",
      "[7270988666945721113120809463312144500555280693674, 22961665442842143903220898566890700943449852505536, 20613262322062277119573630365746595127182499134519, 25666449378145533821257044298909866450131224188388, 49648777350264920336257917599386766751429992537949, 23262138535430815965897209751063602705729030703607, 20663312364214574545779485666796513311973587596483, 52792865455644029778549137754509322291183002304751, 53567916807806914103914877537850847808169443022861, 22453991272873058234492300158377019032521111612219, 10235051201618776623875359480548401671315373635138]\n",
      "[32083111036126459261180639309633731096371489192527, 50806696935996374692315166258825721820101871429809, 22816956567510665168741835293166565473220634279942, 43308947551399742961005592210604413184580574131025, 18080880950383506422733101513743633287139900422079, 36371123739210616465996057708704981096130718166775, 43229146032083899182761576784977586741533298306210, 29013720512811045293191661764715330706360614478768, 21498702084474512676857271979017679975982111913956, 20843916427861693662232393682374652836468951328859, 39630638501985917651015259219491768933792417479908]\n"
     ]
    }
   ],
   "source": [
    "c1_list = []\n",
    "c2_list = []\n",
    "\n",
    "for k in range(11):\n",
    "    cnt = 0\n",
    "    c1_sum = 0\n",
    "    c2_sum = 0\n",
    "    \n",
    "    messages = df.iloc[:, k].values\n",
    "\n",
    "    for i, message in enumerate(messages, 1):\n",
    "        if message is not None and message == message:\n",
    "            c1, c2 = map(int, message.strip(\"()\").split(\",\"))\n",
    "            c1_sum += c1\n",
    "            c2_sum += c2\n",
    "            cnt += 1\n",
    "    \n",
    "    print(c1_sum//cnt, \",\", c2_sum//cnt)\n",
    "\n",
    "    c1_list.append(c1_sum//cnt)\n",
    "    c2_list.append(c2_sum//cnt)\n",
    "\n",
    "print(c1_list)\n",
    "print(c2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Age\", \"Sex\", \"ChestPainType\", \"RestingBloodPressure\", \"Cholesterol\",\n",
    "    \"FastingBloodSugar\", \"RestingECG\", \"MaximumHeartRate\", \"ExerciseAngina\",\n",
    "    \"Oldpeak\", \"ST_Slope\", \"HeartDisease\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = pd.DataFrame()\n",
    "\n",
    "for k in range(11):\n",
    "    \n",
    "    messages = df.iloc[:, k].values\n",
    "\n",
    "    imputed_column = []\n",
    "\n",
    "    for i, message in enumerate(messages, 1):\n",
    "        if message is None:\n",
    "            c1 = c1_list[k]\n",
    "            c2 = c2_list[k]\n",
    "        \n",
    "        if message is not None and message == message:\n",
    "            c1, c2 = map(int, message.strip(\"()\").split(\",\"))\n",
    "\n",
    "        imputed_column.append(f\"({c1},{c2})\")\n",
    "\n",
    "    imputed_data[column_names[k]] = imputed_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load('13_CC_Scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Thesis - Paper - Proper\\Resources\\custom_tuple_scaler.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  c2_values = X.applymap(self._extract_c2)\n"
     ]
    }
   ],
   "source": [
    "df_scaled = scaler.transform(imputed_data)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=imputed_data.columns)\n",
    "df_scaled.to_csv('14_CC_Scaled_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State for Train-Test Split: 2419\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "random_state = None\n",
    "\n",
    "with open(\"13_CC_Hyperparameters.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"train_test_split\"):\n",
    "            param_str = line.split(\"Hyperparameters: \")[1].strip()\n",
    "            params = ast.literal_eval(param_str)\n",
    "            random_state = params.get(\"random_state\")\n",
    "\n",
    "print(\"Random State for Train-Test Split:\", random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Same Test Data: \n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "Calculated \t Reference \t | Calculated \t Reference \t | Calculated \t Reference \t | Calculated \t Reference\n",
      "F1-score \t F1-score \t | Accuracy \t Accuracy \t | Precision \t Precision \t | Recall \t Recall\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      " 92.86%, \t  92.86% \t |  91.23%, \t  91.23% \t |  91.63%, \t  91.63% \t |  94.12%, \t  94.12%\n",
      "\n",
      "\n",
      "With Different Test Data: \n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "Calculated \t Reference \t | Calculated \t Reference \t | Calculated \t Reference \t | Calculated \t Reference\n",
      "F1-score \t F1-score \t | Accuracy \t Accuracy \t | Precision \t Precision \t | Recall \t Recall\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      " 98.08%, \t  92.86% \t |  97.80%, \t  91.23% \t |  97.66%, \t  91.63% \t |  98.50%, \t  94.12%\n",
      " 98.25%, \t  92.86% \t |  97.99%, \t  91.23% \t |  97.78%, \t  91.63% \t |  98.72%, \t  94.12%\n",
      " 97.96%, \t  92.86% \t |  97.68%, \t  91.23% \t |  97.64%, \t  91.63% \t |  98.27%, \t  94.12%\n",
      " 97.93%, \t  92.86% \t |  97.68%, \t  91.23% \t |  97.40%, \t  91.63% \t |  98.47%, \t  94.12%\n",
      " 98.12%, \t  92.86% \t |  97.87%, \t  91.23% \t |  97.75%, \t  91.63% \t |  98.49%, \t  94.12%\n",
      " 97.97%, \t  92.86% \t |  97.68%, \t  91.23% \t |  97.66%, \t  91.63% \t |  98.29%, \t  94.12%\n",
      " 98.39%, \t  92.86% \t |  98.17%, \t  91.23% \t |  97.97%, \t  91.63% \t |  98.82%, \t  94.12%\n",
      " 97.91%, \t  92.86% \t |  97.62%, \t  91.23% \t |  97.54%, \t  91.63% \t |  98.28%, \t  94.12%\n",
      " 98.18%, \t  92.86% \t |  97.93%, \t  91.23% \t |  97.87%, \t  91.63% \t |  98.50%, \t  94.12%\n",
      " 98.10%, \t  92.86% \t |  97.80%, \t  91.23% \t |  97.68%, \t  91.63% \t |  98.51%, \t  94.12%\n",
      " 98.14%, \t  92.86% \t |  97.87%, \t  91.23% \t |  97.77%, \t  91.63% \t |  98.50%, \t  94.12%\n",
      " 98.05%, \t  92.86% \t |  97.80%, \t  91.23% \t |  97.73%, \t  91.63% \t |  98.37%, \t  94.12%\n",
      " 98.22%, \t  92.86% \t |  97.99%, \t  91.23% \t |  97.95%, \t  91.63% \t |  98.48%, \t  94.12%\n",
      " 98.02%, \t  92.86% \t |  97.74%, \t  91.23% \t |  97.76%, \t  91.63% \t |  98.28%, \t  94.12%\n",
      " 98.08%, \t  92.86% \t |  97.80%, \t  91.23% \t |  97.66%, \t  91.63% \t |  98.50%, \t  94.12%\n"
     ]
    }
   ],
   "source": [
    "# Best Model validation\n",
    "#-----------------------\n",
    "\n",
    "rf = joblib.load('12_SP_Model_RF.joblib')\n",
    "\n",
    "file_path = \"13_CC_Matrices_RF.txt\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    lines = f.read().strip().splitlines()\n",
    "    reference_f1 = float(lines[0])\n",
    "    reference_acc = float(lines[1])\n",
    "    reference_pre = float(lines[2])\n",
    "    reference_rec = float(lines[3])\n",
    "\n",
    "print(\"With Same Test Data: \")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"Calculated \\t Reference \\t | Calculated \\t Reference \\t | Calculated \\t Reference \\t | Calculated \\t Reference\")\n",
    "print(f\"F1-score \\t F1-score \\t | Accuracy \\t Accuracy \\t | Precision \\t Precision \\t | Recall \\t Recall\")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------------\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_scaled, Y, test_size=0.2, random_state=random_state)\n",
    "rf_pred = rf.predict(X_test)\n",
    "calculated_f1 = f1_score(Y_test, rf_pred)\n",
    "calculated_acc = accuracy_score(Y_test, rf_pred)\n",
    "calculated_pre = precision_score(Y_test, rf_pred)\n",
    "calculated_rec = recall_score(Y_test, rf_pred)\n",
    "print(f\"{calculated_f1 * 100 : .2f}%, \\t {reference_f1 * 100 : .2f}% \\t | {calculated_acc * 100 : .2f}%, \\t {reference_acc * 100 : .2f}% \\t | {calculated_pre * 100 : .2f}%, \\t {reference_pre * 100 : .2f}% \\t | {calculated_rec * 100 : .2f}%, \\t {reference_rec * 100 : .2f}%\")\n",
    "\n",
    "print(\"\\n\\nWith Different Test Data: \")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"Calculated \\t Reference \\t | Calculated \\t Reference \\t | Calculated \\t Reference \\t | Calculated \\t Reference\")\n",
    "print(f\"F1-score \\t F1-score \\t | Accuracy \\t Accuracy \\t | Precision \\t Precision \\t | Recall \\t Recall\")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------------\")\n",
    "for i in range(15):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df_scaled, Y, test_size=0.9)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    calculated_f1 = f1_score(Y_test, rf_pred)\n",
    "    calculated_acc = accuracy_score(Y_test, rf_pred)\n",
    "    calculated_pre = precision_score(Y_test, rf_pred)\n",
    "    calculated_rec = recall_score(Y_test, rf_pred)\n",
    "\n",
    "    print(f\"{calculated_f1 * 100 : .2f}%, \\t {reference_f1 * 100 : .2f}% \\t | {calculated_acc * 100 : .2f}%, \\t {reference_acc * 100 : .2f}% \\t | {calculated_pre * 100 : .2f}%, \\t {reference_pre * 100 : .2f}% \\t | {calculated_rec * 100 : .2f}%, \\t {reference_rec * 100 : .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Same Test Data: \n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "Calculated \t Reference \t | Calculated \t Reference \t | Calculated \t Reference \t | Calculated \t Reference\n",
      "F1-score \t F1-score \t | Accuracy \t Accuracy \t | Precision \t Precision \t | Recall \t Recall\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      " 100.00%, \t  100.00% \t |  100.00%, \t  100.00% \t |  100.00%, \t  100.00% \t |  100.00%, \t  100.00%\n",
      "\n",
      "\n",
      "With Different Test Data: \n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "Calculated \t Reference \t | Calculated \t Reference \t | Calculated \t Reference \t | Calculated \t Reference\n",
      "F1-score \t F1-score \t | Accuracy \t Accuracy \t | Precision \t Precision \t | Recall \t Recall\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      " 88.03%, \t  100.00% \t |  85.85%, \t  100.00% \t |  84.88%, \t  100.00% \t |  91.43%, \t  100.00%\n",
      " 87.89%, \t  100.00% \t |  85.55%, \t  100.00% \t |  84.15%, \t  100.00% \t |  91.98%, \t  100.00%\n",
      " 87.95%, \t  100.00% \t |  85.67%, \t  100.00% \t |  84.20%, \t  100.00% \t |  92.06%, \t  100.00%\n",
      " 87.15%, \t  100.00% \t |  84.88%, \t  100.00% \t |  83.60%, \t  100.00% \t |  91.02%, \t  100.00%\n",
      " 87.50%, \t  100.00% \t |  85.24%, \t  100.00% \t |  83.61%, \t  100.00% \t |  91.77%, \t  100.00%\n",
      " 87.81%, \t  100.00% \t |  85.55%, \t  100.00% \t |  84.14%, \t  100.00% \t |  91.83%, \t  100.00%\n",
      " 87.53%, \t  100.00% \t |  85.24%, \t  100.00% \t |  84.14%, \t  100.00% \t |  91.19%, \t  100.00%\n",
      " 87.67%, \t  100.00% \t |  85.37%, \t  100.00% \t |  84.04%, \t  100.00% \t |  91.62%, \t  100.00%\n",
      " 88.21%, \t  100.00% \t |  85.91%, \t  100.00% \t |  84.79%, \t  100.00% \t |  91.91%, \t  100.00%\n",
      " 87.62%, \t  100.00% \t |  85.37%, \t  100.00% \t |  84.23%, \t  100.00% \t |  91.29%, \t  100.00%\n",
      " 87.67%, \t  100.00% \t |  85.43%, \t  100.00% \t |  84.16%, \t  100.00% \t |  91.50%, \t  100.00%\n",
      " 87.64%, \t  100.00% \t |  85.24%, \t  100.00% \t |  84.28%, \t  100.00% \t |  91.28%, \t  100.00%\n",
      " 87.29%, \t  100.00% \t |  84.82%, \t  100.00% \t |  83.58%, \t  100.00% \t |  91.35%, \t  100.00%\n",
      " 87.85%, \t  100.00% \t |  85.61%, \t  100.00% \t |  84.21%, \t  100.00% \t |  91.82%, \t  100.00%\n",
      " 87.61%, \t  100.00% \t |  85.12%, \t  100.00% \t |  84.11%, \t  100.00% \t |  91.42%, \t  100.00%\n"
     ]
    }
   ],
   "source": [
    "# Fake Model validation\n",
    "#-----------------------\n",
    "\n",
    "rf = joblib.load('12_SP_Fake_Model_RF.joblib')\n",
    "\n",
    "file_path = \"13_CC_Fake_Matrices_RF.txt\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    lines = f.read().strip().splitlines()\n",
    "    reference_f1 = float(lines[0])\n",
    "    reference_acc = float(lines[1])\n",
    "    reference_pre = float(lines[2])\n",
    "    reference_rec = float(lines[3])\n",
    "\n",
    "print(\"With Same Test Data: \")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"Calculated \\t Reference \\t | Calculated \\t Reference \\t | Calculated \\t Reference \\t | Calculated \\t Reference\")\n",
    "print(f\"F1-score \\t F1-score \\t | Accuracy \\t Accuracy \\t | Precision \\t Precision \\t | Recall \\t Recall\")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------------\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_scaled, Y, test_size=0.2, random_state=random_state)\n",
    "rf_pred = rf.predict(X_test)\n",
    "calculated_f1 = f1_score(Y_test, rf_pred)\n",
    "calculated_acc = accuracy_score(Y_test, rf_pred)\n",
    "calculated_pre = precision_score(Y_test, rf_pred)\n",
    "calculated_rec = recall_score(Y_test, rf_pred)\n",
    "print(f\"{calculated_f1 * 100 : .2f}%, \\t {reference_f1 * 100 : .2f}% \\t | {calculated_acc * 100 : .2f}%, \\t {reference_acc * 100 : .2f}% \\t | {calculated_pre * 100 : .2f}%, \\t {reference_pre * 100 : .2f}% \\t | {calculated_rec * 100 : .2f}%, \\t {reference_rec * 100 : .2f}%\")\n",
    "\n",
    "print(\"\\n\\nWith Different Test Data: \")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"Calculated \\t Reference \\t | Calculated \\t Reference \\t | Calculated \\t Reference \\t | Calculated \\t Reference\")\n",
    "print(f\"F1-score \\t F1-score \\t | Accuracy \\t Accuracy \\t | Precision \\t Precision \\t | Recall \\t Recall\")\n",
    "print(f\"--------------------------------------------------------------------------------------------------------------------------\")\n",
    "for i in range(15):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df_scaled, Y, test_size=0.9)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    calculated_f1 = f1_score(Y_test, rf_pred)\n",
    "    calculated_acc = accuracy_score(Y_test, rf_pred)\n",
    "    calculated_pre = precision_score(Y_test, rf_pred)\n",
    "    calculated_rec = recall_score(Y_test, rf_pred)\n",
    "\n",
    "    print(f\"{calculated_f1 * 100 : .2f}%, \\t {reference_f1 * 100 : .2f}% \\t | {calculated_acc * 100 : .2f}%, \\t {reference_acc * 100 : .2f}% \\t | {calculated_pre * 100 : .2f}%, \\t {reference_pre * 100 : .2f}% \\t | {calculated_rec * 100 : .2f}%, \\t {reference_rec * 100 : .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
