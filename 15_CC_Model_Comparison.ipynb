{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import ast  \n",
    "import random\n",
    "import os\n",
    "os.chdir('Resources/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1_CC_Combined_Data.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns=[\"HeartDisease\"])\n",
    "Y = LabelEncoder().fit_transform(df[\"HeartDisease\"])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9336099585062241\n"
     ]
    }
   ],
   "source": [
    "# 1.1 - RF+XGB (F1)\n",
    "#------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=67)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=20, n_estimators=72)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=774)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "assert len(rf_pred) == len(xgb_pred) == len(y_test)\n",
    "\n",
    "combined_pred = [r if r == x else r for r, x in zip(rf_pred, xgb_pred)]\n",
    "\n",
    "combined_f1 = f1_score(y_test, combined_pred)\n",
    "\n",
    "print(combined_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9164490861618799\n"
     ]
    }
   ],
   "source": [
    "# 1.2 - RF+XGB (ACC)\n",
    "#-------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=612, n_estimators=60)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=612)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "assert len(rf_pred) == len(xgb_pred) == len(y_test)\n",
    "\n",
    "combined_pred = [r if r == x else r for r, x in zip(rf_pred, xgb_pred)]\n",
    "\n",
    "combined_acc = accuracy_score(y_test, combined_pred)\n",
    "\n",
    "print(combined_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# 1.3 - RF+XGB (PRE)\n",
    "#--------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=15)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=855, n_estimators=2)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=855)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "assert len(rf_pred) == len(xgb_pred) == len(y_test)\n",
    "\n",
    "combined_pred = [r if r == x else r for r, x in zip(rf_pred, xgb_pred)]\n",
    "\n",
    "combined_pre = precision_score(y_test, combined_pred)\n",
    "\n",
    "print(combined_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "# 1.4 - RF+XGB (REC)\n",
    "#--------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=530)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=46, n_estimators=87)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=46)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "assert len(rf_pred) == len(xgb_pred) == len(y_test)\n",
    "\n",
    "combined_pred = [r if r == x else r for r, x in zip(rf_pred, xgb_pred)]\n",
    "\n",
    "combined_rec = recall_score(y_test, combined_pred)\n",
    "\n",
    "print(combined_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1_CC_Structured_Data.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns=[\"HeartDisease\"])\n",
    "Y = LabelEncoder().fit_transform(df[\"HeartDisease\"])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9409090909090909\n"
     ]
    }
   ],
   "source": [
    "# 2.1 - RF+XGB (F1)\n",
    "#------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=2423)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=419, n_estimators=97)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=419)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "assert len(rf_pred) == len(xgb_pred) == len(y_test)\n",
    "\n",
    "combined_pred = [r if r == x else r for r, x in zip(rf_pred, xgb_pred)]\n",
    "\n",
    "structured_f1 = f1_score(y_test, combined_pred)\n",
    "\n",
    "print(structured_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9148936170212766\n"
     ]
    }
   ],
   "source": [
    "# 2.2 - RF+XGB (ACC)\n",
    "#-------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=284)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=188, n_estimators=92)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=188)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "assert len(rf_pred) == len(xgb_pred) == len(y_test)\n",
    "\n",
    "combined_pred = [r if r == x else r for r, x in zip(rf_pred, xgb_pred)]\n",
    "\n",
    "structured_acc = accuracy_score(y_test, combined_pred)\n",
    "\n",
    "print(structured_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9288702928870293\n"
     ]
    }
   ],
   "source": [
    "# 2.3 - RF+XGB (PRE)\n",
    "#--------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=1237)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=435, n_estimators=99)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=435)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "assert len(rf_pred) == len(xgb_pred) == len(y_test)\n",
    "\n",
    "combined_pred = [r if r == x else r for r, x in zip(rf_pred, xgb_pred)]\n",
    "\n",
    "structured_pre = precision_score(y_test, combined_pred)\n",
    "\n",
    "print(structured_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9813953488372092\n"
     ]
    }
   ],
   "source": [
    "# 2.4 - RF+XGB (REC)\n",
    "#--------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=1219)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=12, n_estimators=87)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=12)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "assert len(rf_pred) == len(xgb_pred) == len(y_test)\n",
    "\n",
    "combined_pred = [r if r == x else r for r, x in zip(rf_pred, xgb_pred)]\n",
    "\n",
    "structured_rec = recall_score(y_test, combined_pred)\n",
    "\n",
    "print(structured_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_f1 = \"13_CC_F1_Score_RF_XGB.txt\"\n",
    "with open(file_path_f1, \"r\") as f:\n",
    "    encrypted_f1 = float(f.read().strip())\n",
    "\n",
    "file_path_acc = \"13_CC_ACC_Score_RF_XGB.txt\"\n",
    "with open(file_path_acc, \"r\") as f:\n",
    "    encrypted_acc = float(f.read().strip())\n",
    "\n",
    "file_path_pre = \"13_CC_PRE_Score_RF_XGB.txt\"\n",
    "with open(file_path_pre, \"r\") as f:\n",
    "    encrypted_pre = float(f.read().strip())\n",
    "\n",
    "file_path_rec = \"13_CC_REC_Score_RF_XGB.txt\"\n",
    "with open(file_path_rec, \"r\") as f:\n",
    "    encrypted_rec = float(f.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "Combined Dataset:\t93.36%\n",
      "Structured Dataset:\t94.09%\n",
      "Encrypted Dataset:\t94.78%\n",
      "\n",
      "Accuracy\n",
      "Combined Dataset:\t91.64%\n",
      "Structured Dataset:\t91.49%\n",
      "Encrypted Dataset:\t92.4%\n",
      "\n",
      "Precision\n",
      "Combined Dataset:\t96.49%\n",
      "Structured Dataset:\t92.89%\n",
      "Encrypted Dataset:\t94.32%\n",
      "\n",
      "Recall\n",
      "Combined Dataset:\t96.88%\n",
      "Structured Dataset:\t98.14%\n",
      "Encrypted Dataset:\t98.2%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score\")\n",
    "print(f'Combined Dataset:\\t{round(combined_f1 * 100, 2)}%')\n",
    "print(f'Structured Dataset:\\t{round(structured_f1 * 100, 2)}%')\n",
    "print(f'Encrypted Dataset:\\t{round(encrypted_f1 * 100, 2)}%')\n",
    "\n",
    "print(\"\\nAccuracy\")\n",
    "print(f'Combined Dataset:\\t{round(combined_acc * 100, 2)}%')\n",
    "print(f'Structured Dataset:\\t{round(structured_acc * 100, 2)}%')\n",
    "print(f'Encrypted Dataset:\\t{round(encrypted_acc * 100, 2)}%')\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(f'Combined Dataset:\\t{round(combined_pre * 100, 2)}%')\n",
    "print(f'Structured Dataset:\\t{round(structured_pre * 100, 2)}%')\n",
    "print(f'Encrypted Dataset:\\t{round(encrypted_pre * 100, 2)}%')\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(f'Combined Dataset:\\t{round(combined_rec * 100, 2)}%')\n",
    "print(f'Structured Dataset:\\t{round(structured_rec * 100, 2)}%')\n",
    "print(f'Encrypted Dataset:\\t{round(encrypted_rec * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
