{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import ast  \n",
    "import random\n",
    "import os\n",
    "os.chdir('Resources/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1_CC_Structured_Data.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop(columns=[\"HeartDisease\"])\n",
    "Y = LabelEncoder().fit_transform(df[\"HeartDisease\"])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.8592964824120602 0.8592964824120602 1\n",
      "2 0.7738693467336684 0.8592964824120602 1\n",
      "3 0.9296482412060302 0.9296482412060302 3\n",
      "4 0.8743718592964824 0.9296482412060302 3\n",
      "5 0.9396984924623115 0.9396984924623115 5\n",
      "6 0.9296482412060302 0.9396984924623115 5\n",
      "7 0.9447236180904522 0.9447236180904522 7\n",
      "8 0.9296482412060302 0.9447236180904522 7\n",
      "9 0.949748743718593 0.949748743718593 9\n",
      "10 0.9246231155778895 0.949748743718593 9\n",
      "11 0.9396984924623115 0.949748743718593 9\n",
      "12 0.9045226130653267 0.949748743718593 9\n",
      "13 0.9296482412060302 0.949748743718593 9\n",
      "14 0.9195979899497487 0.949748743718593 9\n",
      "15 0.9447236180904522 0.949748743718593 9\n",
      "16 0.9195979899497487 0.949748743718593 9\n",
      "17 0.9547738693467337 0.9547738693467337 17\n",
      "18 0.9296482412060302 0.9547738693467337 17\n",
      "19 0.9396984924623115 0.9547738693467337 17\n",
      "20 0.9246231155778895 0.9547738693467337 17\n",
      "21 0.9396984924623115 0.9547738693467337 17\n",
      "22 0.9346733668341709 0.9547738693467337 17\n",
      "23 0.9396984924623115 0.9547738693467337 17\n",
      "24 0.9296482412060302 0.9547738693467337 17\n",
      "25 0.9396984924623115 0.9547738693467337 17\n",
      "26 0.9195979899497487 0.9547738693467337 17\n",
      "27 0.9447236180904522 0.9547738693467337 17\n",
      "28 0.9246231155778895 0.9547738693467337 17\n",
      "29 0.9296482412060302 0.9547738693467337 17\n",
      "30 0.9296482412060302 0.9547738693467337 17\n",
      "31 0.9346733668341709 0.9547738693467337 17\n",
      "32 0.9296482412060302 0.9547738693467337 17\n",
      "33 0.9296482412060302 0.9547738693467337 17\n",
      "34 0.9246231155778895 0.9547738693467337 17\n",
      "35 0.9346733668341709 0.9547738693467337 17\n",
      "36 0.9246231155778895 0.9547738693467337 17\n",
      "37 0.9396984924623115 0.9547738693467337 17\n",
      "38 0.9296482412060302 0.9547738693467337 17\n",
      "39 0.9346733668341709 0.9547738693467337 17\n",
      "40 0.9296482412060302 0.9547738693467337 17\n",
      "41 0.9296482412060302 0.9547738693467337 17\n",
      "42 0.9296482412060302 0.9547738693467337 17\n",
      "43 0.9346733668341709 0.9547738693467337 17\n",
      "44 0.9296482412060302 0.9547738693467337 17\n",
      "45 0.9396984924623115 0.9547738693467337 17\n",
      "46 0.9346733668341709 0.9547738693467337 17\n",
      "47 0.9447236180904522 0.9547738693467337 17\n",
      "48 0.9296482412060302 0.9547738693467337 17\n",
      "49 0.9447236180904522 0.9547738693467337 17\n",
      "50 0.9346733668341709 0.9547738693467337 17\n",
      "51 0.9396984924623115 0.9547738693467337 17\n",
      "52 0.9346733668341709 0.9547738693467337 17\n",
      "53 0.9396984924623115 0.9547738693467337 17\n",
      "54 0.9396984924623115 0.9547738693467337 17\n",
      "55 0.9447236180904522 0.9547738693467337 17\n",
      "56 0.9447236180904522 0.9547738693467337 17\n",
      "57 0.9447236180904522 0.9547738693467337 17\n",
      "58 0.9396984924623115 0.9547738693467337 17\n",
      "59 0.9447236180904522 0.9547738693467337 17\n",
      "60 0.9447236180904522 0.9547738693467337 17\n",
      "61 0.9447236180904522 0.9547738693467337 17\n",
      "62 0.9447236180904522 0.9547738693467337 17\n",
      "63 0.949748743718593 0.9547738693467337 17\n",
      "64 0.9396984924623115 0.9547738693467337 17\n",
      "65 0.949748743718593 0.9547738693467337 17\n",
      "66 0.9346733668341709 0.9547738693467337 17\n",
      "67 0.949748743718593 0.9547738693467337 17\n",
      "68 0.9396984924623115 0.9547738693467337 17\n",
      "69 0.949748743718593 0.9547738693467337 17\n",
      "70 0.9447236180904522 0.9547738693467337 17\n",
      "71 0.9447236180904522 0.9547738693467337 17\n",
      "72 0.9447236180904522 0.9547738693467337 17\n",
      "73 0.9547738693467337 0.9547738693467337 17\n",
      "74 0.9547738693467337 0.9547738693467337 17\n",
      "75 0.9597989949748744 0.9597989949748744 75\n",
      "76 0.9597989949748744 0.9597989949748744 75\n",
      "77 0.9597989949748744 0.9597989949748744 75\n",
      "78 0.9547738693467337 0.9597989949748744 75\n",
      "79 0.9597989949748744 0.9597989949748744 75\n",
      "80 0.9597989949748744 0.9597989949748744 75\n",
      "81 0.9597989949748744 0.9597989949748744 75\n",
      "82 0.9597989949748744 0.9597989949748744 75\n",
      "83 0.9597989949748744 0.9597989949748744 75\n",
      "84 0.9597989949748744 0.9597989949748744 75\n",
      "85 0.9597989949748744 0.9597989949748744 75\n",
      "86 0.9597989949748744 0.9597989949748744 75\n",
      "87 0.9597989949748744 0.9597989949748744 75\n",
      "88 0.9597989949748744 0.9597989949748744 75\n",
      "89 0.9597989949748744 0.9597989949748744 75\n",
      "90 0.9597989949748744 0.9597989949748744 75\n",
      "91 0.9597989949748744 0.9597989949748744 75\n",
      "92 0.9597989949748744 0.9597989949748744 75\n",
      "93 0.9597989949748744 0.9597989949748744 75\n",
      "94 0.9597989949748744 0.9597989949748744 75\n",
      "95 0.9597989949748744 0.9597989949748744 75\n",
      "96 0.9597989949748744 0.9597989949748744 75\n",
      "97 0.9597989949748744 0.9597989949748744 75\n",
      "98 0.9597989949748744 0.9597989949748744 75\n",
      "99 0.9597989949748744 0.9597989949748744 75\n",
      "100 0.9597989949748744 0.9597989949748744 75\n",
      "101 0.9597989949748744 0.9597989949748744 75\n",
      "102 0.9597989949748744 0.9597989949748744 75\n",
      "103 0.9597989949748744 0.9597989949748744 75\n",
      "104 0.9547738693467337 0.9597989949748744 75\n",
      "105 0.9547738693467337 0.9597989949748744 75\n",
      "106 0.9547738693467337 0.9597989949748744 75\n",
      "107 0.9547738693467337 0.9597989949748744 75\n",
      "108 0.9547738693467337 0.9597989949748744 75\n",
      "109 0.9547738693467337 0.9597989949748744 75\n",
      "110 0.949748743718593 0.9597989949748744 75\n",
      "111 0.949748743718593 0.9597989949748744 75\n",
      "112 0.949748743718593 0.9597989949748744 75\n",
      "113 0.9547738693467337 0.9597989949748744 75\n",
      "114 0.949748743718593 0.9597989949748744 75\n",
      "115 0.9547738693467337 0.9597989949748744 75\n",
      "116 0.949748743718593 0.9597989949748744 75\n",
      "117 0.9547738693467337 0.9597989949748744 75\n",
      "118 0.949748743718593 0.9597989949748744 75\n",
      "119 0.9547738693467337 0.9597989949748744 75\n",
      "120 0.9547738693467337 0.9597989949748744 75\n",
      "121 0.9597989949748744 0.9597989949748744 75\n",
      "122 0.9547738693467337 0.9597989949748744 75\n",
      "123 0.9547738693467337 0.9597989949748744 75\n",
      "124 0.9547738693467337 0.9597989949748744 75\n",
      "125 0.9547738693467337 0.9597989949748744 75\n",
      "126 0.949748743718593 0.9597989949748744 75\n",
      "127 0.949748743718593 0.9597989949748744 75\n",
      "128 0.9396984924623115 0.9597989949748744 75\n",
      "129 0.9396984924623115 0.9597989949748744 75\n",
      "130 0.9396984924623115 0.9597989949748744 75\n",
      "131 0.9396984924623115 0.9597989949748744 75\n",
      "132 0.9396984924623115 0.9597989949748744 75\n",
      "133 0.9396984924623115 0.9597989949748744 75\n",
      "134 0.9396984924623115 0.9597989949748744 75\n",
      "135 0.9447236180904522 0.9597989949748744 75\n",
      "136 0.9396984924623115 0.9597989949748744 75\n",
      "137 0.949748743718593 0.9597989949748744 75\n",
      "138 0.9396984924623115 0.9597989949748744 75\n",
      "139 0.949748743718593 0.9597989949748744 75\n",
      "140 0.9447236180904522 0.9597989949748744 75\n",
      "141 0.9547738693467337 0.9597989949748744 75\n",
      "142 0.9447236180904522 0.9597989949748744 75\n",
      "143 0.949748743718593 0.9597989949748744 75\n",
      "144 0.9447236180904522 0.9597989949748744 75\n",
      "145 0.949748743718593 0.9597989949748744 75\n",
      "146 0.949748743718593 0.9597989949748744 75\n",
      "147 0.949748743718593 0.9597989949748744 75\n",
      "148 0.9447236180904522 0.9597989949748744 75\n",
      "149 0.9597989949748744 0.9597989949748744 75\n",
      "150 0.9547738693467337 0.9597989949748744 75\n",
      "151 0.9547738693467337 0.9597989949748744 75\n",
      "152 0.949748743718593 0.9597989949748744 75\n",
      "153 0.9597989949748744 0.9597989949748744 75\n"
     ]
    }
   ],
   "source": [
    "# 2.1 - RF (F1)\n",
    "#--------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "mx=0\n",
    "ind=0\n",
    "#3553 0.8812785388127854 0.9547738693467337 2724\n",
    "\n",
    "for i in range(1, 200):\n",
    "    seed = i\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=2724)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=113, n_estimators=seed)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "\n",
    "    structured_rec = recall_score(y_test, rf_pred)\n",
    "    \n",
    "    if structured_rec>mx:\n",
    "        mx=structured_rec\n",
    "        ind=i\n",
    "\n",
    "    print(i, structured_rec, mx, ind)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
